---
title: "Direct likelihood maximisation using numerical quadrature to approximate intractable terms"
author: "<b>Alessandro Gasparini</b><sup>a</sup>.footnote-ts[<i>a</i>: Department of Health Sciences, University of Leicester, UK<br><i class='fa fa-envelope-o'></i>: ag475@leicester.ac.uk], Keith R Abrams<sup>a</sup>, Michael J Crowther<sup>a</sup>"
date: "April 5<sup>th</sup>, 2017"
output:
  xaringan::moon_reader:
    chakra: Presentation_files/remark-latest.min.js
    css: ["Presentation_files/fonts.css", "Presentation_files/logos.css", "Presentation_files/colours.css", "Presentation_files/uol_remarkjs.css", "Presentation_files/font-awesome.min.css"]
    lib_dir: libs
    nature:
      ratio: '16:9'
      highlightStyle: 'arta'
      highlightLanguage: 'R'
      highlightSpans: true
      countIncrementalSlides: false
---
count: false

```{r, include = FALSE}
if (!requireNamespace("pacman")) install.packages("pacman")
if (!requireNamespace("devtools")) install.packages("devtools")
if (!requireNamespace("gganimate")) devtools::install_github("dgrtwo/gganimate")
if (!requireNamespace("uolvid")) devtools::install_github("ellessenne/uolvid")

pacman::p_load("gganimate", "ggplot2", "fastGHQuad", "dplyr", "tidyr", "knitr", "stringr", "uolvid")
opts_chunk$set(echo = FALSE, dpi = 300, message = FALSE, warning = FALSE, tidy = FALSE)
```

# Outline

1. Introduction and methods

--

2. Simulation study: analytic formulae vs Gaussian quadrature

--

3. Simulation study: survival models with log-normal frailties

--

4. Application with R

--

5. Conclusions

---
# About me

* Currently a first-year PhD student at the Department of Health Sciences, University of Leicester;

--

* Previous education: BSc in Statistics and Computing Technologies from University of Padua, Italy, and MSc in Biostatistics and Experimental Statistics from University of Milano-Bicocca, Italy;

--

* PhD project: 
    - joint modelling of longitudinal and survival data;
    - modelling the visiting process;
    - joint modelling of multiple biomarkers and their association with survival;
    - model discrimination tools to evaluate multiple predictive biomarkers;
    - application to health records data and cardiovascular epidemiology.

---
class: center, middle, inverse
count: false
# Introduction and methods

---
# Models with intractable terms

* Survival model with shared frailty term:

$$h_{ij} = h_0 (t) \exp(\beta ^ T Z_{ij} + v_i),$$
$$L_i = \int_{-\infty} ^ {+\infty} \prod_{j = 1} ^ {n_i} \left[ h_{ij}(x_{ij}) \right] ^ {\Delta_{ij}} \exp \left[ -\int_0 ^ {x_{ij}}  h_{ij}(t) \ d t \right] f_{\theta}(v_i) \ d v_i$$
???
The likelihood of many modern statistical models often includes terms that are analytically intractable, such a survival models with frailties, and joint models for longitudinal and survival data. 

Analogously, frailty ~~ random effect

Examples: survival models with recurrent events, IPD meta-analysis, ...

--

* Joint model for longitudinal and survival data:

$$h(t | M_i(t), w_i) = h_0 (t) \exp(\gamma ^ T w_i + \alpha m_i(t)),$$
$$L_i = \int_{-\infty} ^ {+\infty} P(T_i, d_i | b_i; \theta_t) \left[ \prod_{j = 1} ^ {n_i} P(y_i(t_{ij}) | b_i; \theta_y) \right] P(b_i; \theta_{b_i}) \ db_i$$

???

Joint model likelihood: integral of survival submodel P(T_i, d_i) x mixed model P(y_i(t_ij)) x random effects distribution P(b_i).

Examples: healthcare data with multiple, itermittently observed biomarkers, dynamic prediction models, accounting for measurement error, ... 

--

* ...

???

Flexible parametric survival models with frailties or random effects, GLMMs, ...

---
# Estimation options

* The expectation-maximisation [EM] algorithm:

> E step: calculate E[ll(&theta;| X, Z)] given &theta;<sup>t</sup>

> M step: find argmax(E[ll(&theta;| X, Z)]) = &theta;<sup>t+1</sup>

???

The EM method requires effort in coding the E-M steps; in the E-step, the unknown random effects are treated as missing values.

--

* Bayesian approach, using Markov Chain Monte Carlo [MCMC] techniques:

> Choose prior distributions for the model parameters

> Derive posterior distributions for the model parameters

--

* Direct likelihood maximisation:

> Likelihood can be easily evaluated

> Many general purpose optimisers are readily available

???

If closed-form MLEs are not available for a model but the (log-)likelihood can easily be evaluated, one should, before doing anything more sophisticated, simply use a general-purpose numerical optimiser in an attempt to maximise that likelihood, subject to any constraints that there may be on parameters. If that succeeds, there will be no need to derive and code the E and M steps in order to implement the EM algorithm.

Let's go back for a second to the likelihood of a JM: if we want to evaluate the likelihood, we need to find a way to approximate the integral for which there is no closed form solution

---
# Gaussian quadrature

> In numerical analysis, a quadrature rule is an approximation of the definite integral of a function, usually stated as a weighted sum of function values at specified points within the domain of integration.

--

n-point Gaussian quadrature rule: 

$$\int_X f(x) \ dx = \sum_{i = 1} ^ n w_i f(x_i)$$
???

n-point Gaussian quadrature rule yields an exact approximation for polynomials of degree 2n - 1 or less

--

If we rewrite $f(x)$ as $f(x)=\omega(x)g(x)$, weights and nodes $w_i'$ and $x_i'$ that depend on $\omega(x)$ may give better results:

$$\int_X f(x) \ dx = \int_X \omega(x)g(x) \ dx = \sum_{i = 1} ^ n w_i' g(x_i')$$

A commonly used weighting function is $\omega(x) = e ^ {- x ^ 2}$, which yields the so-called Gauss-Hermite quadrature rule.

???

g(x) approximately polynomial
omega(x) known
w_i: weights
x_i: nodes

--

Alternatives: adaptive quadrature rules, Monte-Carlo integration (and importance sampling), Bayesian quadrature, ...

---
class: center, middle

```{r, include = FALSE}
ff = function(x) dnorm(x) / exp(-x^2)

gh_rules <- lapply(seq(2, 32, by = 5), function(i) {
  gh = gaussHermiteData(i)
  int = ghQuad(f = ff, rule = gh)
  data.frame(x = gh$x, w = gh$w, degree = i, integral = int)}) %>% 
  bind_rows() %>% 
  mutate(integral = paste("Quadrature integral:", formattable::comma(integral, 10)))

p <- ggplot(gh_rules, aes(x = x, y = w, frame = degree)) + geom_segment(aes(xend = x, yend = 0)) + geom_text(aes(x = -8, y = 1, label = integral), hjust = 0, vjust = 0) + stat_function(fun = dnorm, color = "red", lty = "dashed") + theme_bw() + labs(x = "", y = "")
gganimate(p, filename = "Presentation_files/gh.gif", fps = 2, width = 8, height = 4.5)
```

<br>

![](Presentation_files/gh.gif)

---
class: center, middle, inverse
count: false
# Simulation study #1: <br/> Analytic formulae vs Gaussian quadrature

---
# Rationale

* Aim: compare estimation procedure using analytic formulae vs using Gaussian quadrature and approximate integrals;

--

* Parametric survival model with shared frailty:
$$h_{ij}(t_{ij} | \alpha_i) = \alpha_i h_{ij}(t_{ij}) = \alpha_i p \lambda t_{ij} ^ {p - 1} \exp(X_{ij} \beta)$$

???
Weibull parametric survival model, with shape parameter p and scale parameter lambda
Proportional hazards parametrisation
Lambda i.e. intercept explicited there

--

* The cluster-specific contribution to the likelihood is:
$$L_i(\alpha_i) = \alpha_i ^ {D_i} \prod_{j = 1} ^ {n_i} \left[ S_{ij}(t_{ij}) ^ {\alpha_i} \left( h_{ij}(t_{ij}) \right) ^ {d_{ij}} \right]$$

--

* The unconditional contribution to the likelihood is:
$$L_i = \int L_i(\alpha_i) g(\alpha_i) \ d \alpha_i$$

---
# Simulation scenarios

* Weibull baseline hazard with shape p = 0.5, scale &lambda; = 1, and shared Gamma-distributed frailty term;

--

* 1,000 simulations per scenario;

--

* number of clusters: {25, 50, 100, 200}, number of individuals per cluster: {25, 50, 100, 250, 500, 1000};

--

* treatment effect: {-0.50, 0.00, 0.50};

???

i.e. log(HR)

--

* variance of the frailty (&theta;): {0.25, 0.50, 1.00};

--

* number of quadrature nodes<sup>1</sup>.footnote[1: Gauss-Laguerre quadrature rule]: {15, 35, 75, 105}.

---
# Results

> Switching to a shiny app for exploring results...

---
class: center, middle, inverse
count: false
# Simulation study #2: <br/> Parametric survival model with a random effect

---
# Rationale

* Aim: estimate a parametric survival model with intractable terms using Gaussian quadrature;

--

* Parametric survival model with a random treatment effect:
$$h_{ij}(t_{ij} | b_i) = p \lambda t_{ij} ^ {p - 1} \exp \left[ X_{ij} (\beta + b_i) \right]$$

--

* Cluster-specific contribution to the likelihood:
$$L_i = \int_{-\infty} ^ {+\infty} \left[ \prod_{j = 1} ^ {n_i} h_{ij}(t_{ij}) ^ {d_{ij}} S_{ij}(t_{ij}) \right] p(b_i) \ d b_i$$

???
Analogously as before, we integrate out the random effects
Likelihood contribution assuming no delayed entry
p(b_i) is the normal density for the random effects

---
# Simulation scenarios

* Weibull baseline hazard with shape p = 1.5, scale &lambda; = 3, and a random treatment effect;

--

* 1,000 simulations per scenario;

--

* number of clusters: {25, 50, 100, 200}, number of individuals per cluster: {25, 50, 100, 250, 500, 1000};

--

* treatment effect: {-0.50, 0.00, 0.50};

--

* variance of the random effect (&sigma;<sup>2</sup>): {0.25, 0.50, 1.00};

--

* number of quadrature nodes<sup>2</sup>.footnote[2: Gauss-Hermite quadrature rule]: {15, 35, 75, 105}.

---
# Results

> Switching to a shiny app for exploring results...

---
class: center, middle, inverse
count: false
# A quick R example 

---
# Dataset

Data on the recurrence times to infection, at the point of insertion of the catheter, for kidney patients using portable dialysis equipment<sup>+</sup>.footnote[<sup>+</sup>McGilchrist and Aisbett, 1991.]. Catheters may be removed for reasons other than infection, in which case the observation is censored. Each patient has exactly 2 observations.

```{r, echo = TRUE}
data(kidney, package = "survival")
str(kidney)
```

---
# Quadrature likelihood

```{r}
library(pracma); gl_rule = gaussLaguerre(35)
mll = function(pars) {
  p = exp(pars[1])
  lambda = exp(pars[2])
  theta = exp(pars[3])
  beta1 = pars[4]
  beta2 = pars[5]
  lli = vapply(1:max(kidney$id),
                FUN = function(i) {
                 log_hi = log(p) + log(lambda) + (p - 1) * log(kidney$time[kidney$id == i]) + (kidney$age[kidney$id == i] * beta1 + kidney$sex[kidney$id == i] * beta2)
                 log_Si = -lambda * kidney$time[kidney$id == i] ^ p * exp(kidney$age[kidney$id == i] * beta1 + kidney$sex[kidney$id == i] * beta2)
                 Di = sum(kidney$status[kidney$id == i])
                 intgrdq = function(alpha) exp(alpha + Di * log(alpha) + alpha * sum(log_Si) + (1 / theta - 1) * log(alpha) - alpha / theta)
                 vintgrdq = Vectorize(intgrdq)
                 int = sum(gl_rule$w * vintgrdq(gl_rule$x))
                 ll = sum(kidney$status[kidney$id == i] * (log_hi)) - lgamma(1 / theta) - (1 / theta) * log(theta) + log(int) + sum(log(kidney$time[kidney$id == i]))
                 return(ll)},
               FUN.VALUE = numeric(1))
  ll = sum(lli)
  return(-ll)
}
```

```{r, eval = FALSE, echo = TRUE}
# quadrature nodes
library(pracma)
gl_rule = gaussLaguerre(35)

# likelihood
mll = function(pars) {
  p = exp(pars[1])
  lambda = exp(pars[2])
  theta = exp(pars[3])
  beta1 = pars[4]
  beta2 = pars[5]
  lli = # actual code for cluster-specific log-likelihood goes here
  ll = sum(lli)
  return(-ll)
}
```

---
# Starting values

```{r, echo = TRUE}
sr <- survival::survreg(survival::Surv(time, status) ~ age + sex, 
                        dist = "weibull", 
                        data = kidney)

start <- c(log(1 / sr$scale), # p
           log(exp(sr$coef[1]) ^ (-1 / sr$scale)), # lambda
           log(1), # theta
           -sr$coef[2] * (1 / sr$scale), # beta1
           -sr$coef[3] * (1 / sr$scale)) # beta2
names(start) <- c("p", "lambda", "theta", "age", "sex")
start
```

---
# Optimise

```{r, echo = TRUE}
system.time({
  out <- optim(fn = mll, par = start, hessian = TRUE, method = "BFGS")
  out$stderr <- sqrt(diag(solve(out$hessian)))
})
```

```{r}
names(out$stderr) <- names(out$par)
```

```{r, echo = TRUE}
out$par
out$stderr
```

Other readily available general purpose optimisers: `nlm()`, `marqLevAlg()` from package `marqLevAlg`, `bobyqa()` from package `minqa`, ...

---
# Discussion

1. Gaussian quadrature works well compared to analytical formulae; 

--

2. Gaussian quadrature works well in settings where analytical formulae are not available;

--

3. Direct likelihood maximisation is straightforward to implement.

---
class: back-slide
count: false

# References

* MacDonald IL, _Numerical maximisation of likelihood: a neglected alternative to EM?_. 2014, International Statistical Review, 82(2):296-308;

* Liu Q, and Pierce DA, _A note on Gauss-Hermite quadrature_. 1994, Biometrika, 81(3):624-629;

* Robert PC and Casella G, _Introducing Monte Carlo methods with R_. 2010, Springer-Verlag, New York;

* Crowther MJ, Look MP, and Riley RD, _Multilevel mixed effects parametric survival models using adaptive Gauss-Hermite quadrature with application to recurrent events and individual participant data meta-analysis_. 2014, Statistics in Medicine, 33(22):3844-3858;

* McGilchrist CA and Aisbett CQ, _Regression with frailty in survival analysis_. 1991, Biometrics, 47:461-66;

* R Code and slides on my Github page: [https://github.com/ellessenne/SAFJR17](https://github.com/ellessenne/SAFJR17)

* E-mail: [ag475@leicester.ac.uk](mailto:ag475@leicester.ac.uk)
